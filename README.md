# Book_TensorFlow_Tutorial

---

## „ÄΩÔ∏èIntroduction:
Tensorflow is an open source software library for machine learning in a variety of conceptual and language tasks, currently hosted by 50 different Google research teams and products, including Speech Recognition, Gmail, Google Photos and Search, many of which have previously used Distlife. Is used. Tensorflow was originally used internally by the Google Brain Research Center team, but was later released on November 9, 2015 under the Apache License.<br>
There are many reasons why gray spectrum images on a computer are usually stored as n ‚àó m matrices (color images with larger dimensions such as n ‚àó m ‚àó 3) and when we have a bunch of images (for example k image), we have to measure the dimensions of the matrices as n ‚àó m ‚àó k (in color images n ‚àó m ‚àó 3 ‚àó k), caused the tensor flow design to use the tensor structure data to store the values and data type of the variables. But the most important reason for the use of tensorflowers is in fact the ease of managing the weights and amounts of neurons in different layers in deep neural networks and deep learning.<br>





| Front Book Cover  | Back Book Cover  |
|-----------|--------------------|
|<p><img src="https://raw.githubusercontent.com/Mohammadimh76/Book_TensorFlow_Tutorial/main/Cover/Front_TensorFlow.jpeg"></p>|<p><img src="https://raw.githubusercontent.com/Mohammadimh76/Book_TensorFlow_Tutorial/main/Cover/Back_TensorFlow.jpeg"></p>|
|  <b>Book Name</b>   |   TensorFlow Tutorial  |
| <b>Authors</b>    |   M.H.Mohammadi, S.Y.Moradi |
| <b>language</b>    |  Persian   |
| <b>Printed in the</b>    |  IRAN   |
| <b>Publisher</b>    |   [Arna Publication](http://arnapub.com/)  |
| <b>First Printing Edition</b>    |   Mar,2021  |
| <b>Print Length</b>    |  394   |
| <b>ISBN</b>    |  ‚Ä´‚Ä¨‚Ä≠‚Ä¨‚Ä≠978-622-291-016-7   |

---

<div class="nav">

## Contents
* [Chapter 1](#chapter-1): <i>TensorFlow Tutorial</i>
* [Chapter 2](#chapter-2): <i>TensorFlow Basics</i>
* [Chapter 3](#chapter-3): <i>TensorFlow Perceptron</i>
* [Chapter 4](#chapter-4): <i>ANN in TensorFlow</i>
* [Chapter 5](#chapter-5): <i>Linear Regression</i>
* [Chapter 6](#chapter-6): <i>CNN in TensorFlow</i>
* [Chapter 7](#chapter-7): <i>RNN in TensorFlow</i>
* [Chapter 8](#chapter-8): <i>Style Transferring</i>
* [Chapter 9](#chapter-9): <i>TensorBoard</i>
* [Chapter 10](#chapter-10): <i>Differences</i>
* [Chapter 11](#chapter-11): <i>Object Detection</i>
* [Chapter 12](#chapter-12): <i>TensorFlow Debugging</i>
* [Chapter 13](#chapter-13): <i>Miscellaneous Topics</i>


üî∏ [Authors](#authors)<br>
üî∏ [Demo](#demo)<br>
üî∏ [Buy](#buy)<br>
üî∏ [BookCollection](#bookcollection)<br>

</div>

<main>

<article id="chapter-1">

## Chapter 1
- ### TensorFlow Tutorial
TensorFlow is one of the famous deep learning frameworks, developed by the Google Team. It is a free and open-source software library and designed in Python programming language, this tutorial is designed in such a way that we can easily implement deep learning projects on TensorFlow in an easy and efficient way.<br>

#### üîπ Topics in this chapter include
| <b>Chapter 1</b>  |   |   | 
|-----------|--------------------|-----------|
|1-1 TensorFlow Tutorial |1-4 Installation Through conda |1-7 TensorFlow Playground |
|1-2 What is TensorFlow |1-5 Architecture of TensorFlow | |
|1-3 Installation Through pip |1-6 Advantage & Disadvantage | |


</article>

<article id="chapter-2">

## Chapter 2
- ### TensorFlow Basics
TensorFlow is a machine learning framework and developed by Google Brain Team. It is derived from its core framework: Tensor. In TensorFlow, all the computations involve tensors. A tensor is a vector or a matrix of n-dimensions which represents the types of data. All the values in a TensorFlow identify data type with a known shape. The shape of the data is the dimension of the matrix or array.<br>

#### üîπ Topics in this chapter include
| <b>Chapter 2</b>  |
|-----------|
|2-1 TensorFlow Basics |


</article>

<article id="chapter-3">

## Chapter 3
- ### TensorFlow Perceptron
The perceptron is a single processing unit of any neural network. Frank Rosenblatt first proposed in 1958 is a simple neuron which is used to classify its input into one or two categories. Perceptron is a linear classifier, and is used in supervised learning. It helps to organize the given input data.<br>
A perceptron is a neural network unit that does a precise computation to detect features in the input data. Perceptron is mainly used to classify the data into two parts. Therefore, it is also known as Linear Binary Classifier.<br>
etc<br>

#### üîπ Topics in this chapter include
| <b>Chapter 3</b>  |   |   | 
|-----------|--------------------|-----------|
|3-1 Single Layer Perceptron |3-2 Hidden Layer Perceptron |3-3 Multi-layer Perceptron |


</article>

<article id="chapter-4">

## Chapter 4
- ### ANN in TensorFlow
Machine learning is the branch of artificial intelligence (AI) which provide the ability to learning automatically learn and improve from experience. It was first introduced in 1959 by Arthur Samuel.<br>
The primary aim is to allow the computer to learn automatically without human involvement or assistance and adjust actions accordingly. Many problems are historical very easy for humans, and very difficult for networks, Machine learning (deep learning in particular) is currently our best solution for many of those problems.<br>
For example, medical diagnosis, image processing, prediction, classification, regression etc.<br>

#### üîπ Topics in this chapter include
| <b>Chapter 4</b>  |   | 
|-----------|--------------------|
|4-1 What is Machine Learning |4-3 Implementation of Neural Network |
|4-2 Artificial Neural Network |4-4 Classification of Neural Network |

</article>

<article id="chapter-5">

## Chapter 5
- ### Linear Regression
Linear Regression is a machine learning algorithm that is based on supervised learning. It performs a regression function. The regression models a target predictive value based on the independent variable. It is mostly used to detect the relation between variables and forecasts.<br>
Linear regression is a linear model; for example, a model that assumes a linear relationship between an input variable (x) and a single output variable (y). In particular, y can be calculated by a linear combination of input variables (x).<br>
Linear regression is a prevalent statistical method that allows us to learn a function or relation from a set of continuous data. For example, we are given some data point of x and the corresponding, and we need to know the relationship between them, which is called the hypothesis.<br>

#### üîπ Topics in this chapter include
| <b>Chapter 5</b>  |   |
|-----------|
|5-1 Linear Regression | 


</article>

<article id="chapter-6">

## Chapter 6
- ### CNN in TensorFlow
Convolutional Neural Network is one of the technique to do image classification and image recognition in neural networks. It is designed to process the data by multiple layers of arrays. This type of neural network is used in applications like image recognition or face recognition. The primary difference between CNN and other neural network is that CNN takes input as a two-dimensional array. And it operates directly on the images rather than focusing on feature extraction which other neural networks do.<br>
etc<br>

#### üîπ Topics in this chapter include
| <b>Chapter 6</b>  |   |   | 
|-----------|--------------------|-----------|
|6-1 CNN Introduction |6-3 Training of CNN |6-5 CIFAR-10 & CIFAR-100 Dataset |
|6-2 Working of CNN |6-4 MNIST Dataset in CNN | |

</article>

<article id="chapter-7">
  
## Chapter 7
- ### RNN in TensorFlow
A recurrent neural network (RNN) is a kind of artificial neural network mainly used in speech recognition and natural language processing (NLP). RNN is used in deep learning and in the development of models that imitate the activity of neurons in the human brain.<br>
Recurrent Networks are designed to recognize patterns in sequences of data, such as text, genomes, handwriting, the spoken word, and numerical time series data emanating from sensors, stock markets, and government agencies.<br>
A recurrent neural network looks similar to a traditional neural network except that a memory-state is added to the neurons. The computation is to include a simple memory.<br>
etc<br>

#### üîπ Topics in this chapter include
| <b>Chapter 7</b>  |   |   | 
|-----------|--------------------|-----------|
|7-1 RNN Introduction |7-4 LSTM RNN in Tensorflow |7-7 CNN vs RNN|
|7-2 Working of RNN |7-5 Training of RNN | |
|7-3 RNN Time Series |7-6 Types of RNN | |

</article>

<article id="chapter-8">

## Chapter 8
- ### Style Transferring
Neural Style Transfer (NST) refers as a class of software algorithm manipulate digital images, or videos, or adopt the appearance or visual style of another image. When we implement the algorithm, we define two distances; one for the content (Dc) and another for the form (Ds).<br>
In the topic, we will implement an artificial system based on Deep Neural Network, which will create images of high perceptual quality. The system will use neural representation to separate, recombine content-image (a style image) as input, and returns the content image as it is printed using the artistic style of the style image.<br>
Neural style transfer is an optimization technique mainly used to take two images- a content image and a style reference image and blend them. So, the output image looks like the content image to match the content statistics of the content image and style statistics of the style reference image. These statistics are derived from the images using a convolutional network.<br>
etc<br>

#### üîπ Topics in this chapter include
| <b>Chapter 8</b>  |   |    
|-----------|--------------------|
|8-1 Style Transferring in TensorFlow |8-3 Process of Style Transferring |
|8-2 Gram Matrix in Style Transferring |8-4 Working of Style Transferring |


</article>

<article id="chapter-9">

## Chapter 9
- ### TensorBoard
TensorFlow is a visualization tool, which is called the TensorBoard. It is used for analyzing the Data flow graph and used to understand machine-learning models. TensorBoard is the interface used to visualize the graph and many tools to understand, debug, and optimize the model.<br>
The important feature of TensorBoard is that it includes a view of different types of statistics about the parameters and details of any graph in a vertical alignment.<br>
The deep neural network includes up to 36,000 nodes. TensorFlow helps in collapsing these nodes in high in collapsing these nodes in high-level blocks and highlighting the identical structures. This allows better analysis of the graph, focusing on the primary sections of the computation graph.<br>
etc<br>

#### üîπ Topics in this chapter include
| <b>Chapter 9</b>  | 
|-----------|
|9-1 TensorBoard |


</article>

<article id="chapter-10">
  
## Chapter 10
- ### Differences
- Difference between TensorFlow and PyTorch
- Difference between TensorFlow and Keras
- Difference between TensorFlow and Theano
- Difference between TensorFlow and Caffe

#### üîπ Topics in this chapter include
| <b>Chapter 10</b>  |   |   
|-----------|--------------------|
|10-1 TensorFlow vs PyTorch |10-3 TensorFlow vs Theano |
|10-2 TensorFlow vs Keras |10-4 TensorFlow vs Caffe |


</article>

<article id="chapter-11">

## Chapter 11
- ### Object Detection
Object detection is a process of discovering real-world object detail in images or videos such as cars or bikes, TVs, flowers, and humans. It allows identification, localization, and identification of multiple objects within an image, giving us a better understanding of an image. It is used in applications such as image retrieval, security, surveillance, and the Advanced Driver Assistance System (ADAS).<br>
etc<br>

#### üîπ Topics in this chapter include
| <b>Chapter 11</b>  |   |   | 
|-----------|--------------------|-----------|
|11-1 Object Detection |


</article>

<article id="chapter-12">
  
## Chapter 12
- ### TensorFlow Debugging
Debugging is a tedious and challenging task. We have to written code and identifying problems through tensorflow debugging. Typically there are many guides, and the process of debugging is often well documented for many languages and frameworks.<br>
TensorFlow has its debugger called the tfdbg TensorFlow Debugging, which lets us observe the essential working and the state of the running graph. These are difficult to debug with any debuggers like pdb in python.<br>
This tutorial will deal with teaching us how to use the tfdbg CLI to debug the appearance of nans and icons, which are the most common types of bugs found in the tensor flow. Given below is a low-level API example.<br>
etc<br>

#### üîπ Topics in this chapter include
| <b>Chapter 12</b>  |   |   
|-----------|--------------------|
|12-1 TensorFlow Debugging |12-2 Fixing Problem |


</article>

<article id="chapter-13">
  
## Chapter 13
- ### Miscellaneous Topics

#### üîπ Topics in this chapter include
| <b>Chapter 13</b>  |   |   | 
|-----------|--------------------|-----------|
|13-1 Forming Graphs |13-3 Tensorflow APIs |13-5 Tensorflow Single and Multiple GPU |
|13-2 Audio Recognition |13-4 Tensorflow Security |13-6 Tensorflow Mobile |


</article>




---
<article id="authors">

## Authors

### The First: "Mohammad Hossein Mohammadi"

<p align="center">
  <img width="360" height="276" src="https://raw.githubusercontent.com/Mohammadimh76/Book_TensorFlow_Tutorial/main/Authors/MohammadHosseinMohammadi.jpeg">
</p>

Iam currently a Final-year BS.c student at the Department of Computer Engineering, Islamic Azad University, Najafabad Branch (IAUN) (Rank in CWUR) where I am a member of the Bioinformatics Laboratory (BL), advised by Prof. Mohammad Naderi Dehkordi. my research involves machine vision, deep learning, and neural networks. where I will complete my thesis on Accurate and Early Identification of Diabetes and it's Affecting Factors.

Prior to BL, I finished my Diploma - Mathematics and Physics in Sheikh Ansari Highschool, in September 2015. I tried to use my Diploma to build a solid bedrock for my future research. So in addition to taking many optional bachelor-level courses on math and computer science. I spent 6 months as an intern Programmer at the "CoTech" in Isfahan.

#### My main research interests
- Artificial Intelligence, Machine Learning
- Optimization Algorithm, Neural & NeuroFuzzy Network
- Computer Vision, Signal and Image Processing

üåê ùêèùêûùê´ùê¨ùê®ùêßùêöùê• ùêèùêöùê†ùêû "ùêåùê®ùê°ùêöùê¶ùê¶ùêöùêù ùêáùê®ùê¨ùê¨ùêûùê¢ùêß ùêåùê®ùê°ùêöùê¶ùê¶ùêöùêùùê¢" üëâ [mohammadimh76.github.io](https://mohammadimh76.github.io/)<br>
üìß ùêÑùê¶ùêöùê¢ùê•: m.h.mohammadimir2017@gmail.com

============================================================================

### The Second: "Seyed Yahya Moradi"

<p align="center">
  <img width="320" height="318" src="https://raw.githubusercontent.com/Mohammadimh76/Book_TensorFlow_Tutorial/main/Authors/SeyedYahyaMoradi.jpeg">
</p>

I am Biomedical Engineer from University of Isfahan. My research interests is Non-Invasive Brain Stimulation, Neuroscience, Brain Mapping & Connectivity, Biomedical AI & IOT, Biosignal Processing.

- Brain stimulation techniques such as tDCS, tACS, tRNS, TMS, Theta-Burst Stimulation (TBS) and Magnetic Seizure Therapy (MST)<br>
- Sleep, Plasticity, Perception, Vision, Navigation<br>
- Q/EEG Decoding; Source Localization; Beamforming; Blind source separation<br>
- Causal Inference; Big Data; Unsupervised & Online learning; Expert System<br>
- Chaos and Fractal Theory<br>

üåê ùêèùêûùê´ùê¨ùê®ùêßùêöùê• ùêèùêöùê†ùêû "ùêíùêûùê≤ùêûùêù ùêòùêöùê°ùê≤ùêö ùêåùê®ùê´ùêöùêùùê¢" üëâ [symoradi.website2.me](http://symoradi.website2.me/)<br>
üìß ùêÑùê¶ùêöùê¢ùê•: s.yahyamoradi@yahoo.com 


---
---

<article id="demo">
  
## Demo 

üëáClick on the link below to see the E-Book Demo!üëáüòâ

## (E-Book Demo): üî∫(Coming Soon)üî∫


</article>

---

<article id="buy">

## üõíBuy

| Amazon (Kindle Edition) | Taaghche  |
|-----------|--------------------|
| <p align="center"><img width="250" height="75" src="https://raw.githubusercontent.com/Mohammadimh76/Book_AStepByStepGuidetoPatentingInIran/main/Stores_logo/Amazon_logo.svg.png"></p> | [<p align="center"><img width="250" height="86" src="https://raw.githubusercontent.com/Mohammadimh76/Book_AStepByStepGuidetoPatentingInIran/main/Stores_logo/Taaghche_logo.jpg"></p>](https://taaghche.com/book/94873/%D8%A2%D9%85%D9%88%D8%B2%D8%B4-%D8%AA%D9%86%D8%B3%D9%88%D8%B1%D9%81%D9%84%D9%88) |


</article>

---


## BookCollection

<article id="bookcollection">
  
|[ArtificialIntelligence](https://github.com/mmohammadi4820/Book_ArtificialIntelligence)  |[ComprehensiveDatabases<br>Training](https://github.com/mmohammadi4820/Book_ComprehensiveDatabasesTraining) |[SoftwareEngineering<br>Training](https://github.com/mmohammadi4820/Book_ComprehensiveDatabasesTraining)  |[SoftwareTesting<br>Tutorial](https://github.com/mmohammadi4820/Book_SoftwareTesting_Tutorial) |
|-----------|--------------------|-----------|--------------------|
|[<p><img src="https://raw.githubusercontent.com/Mohammadimh76/Book_TensorFlow_Tutorial/main/Cover/Book_ArtificialIntelligence.jpeg"></p>](https://github.com/mmohammadi4820/Book_ArtificialIntelligence)|[<p><img src="https://raw.githubusercontent.com/Mohammadimh76/Book_TensorFlow_Tutorial/main/Cover/Book_DataBase.jpeg"></p>](https://github.com/mmohammadi4820/Book_ComprehensiveDatabasesTraining) |[<p><img src="https://raw.githubusercontent.com/Mohammadimh76/Book_TensorFlow_Tutorial/main/Cover/Book_SoftwareEngineering.jpeg"></p>](https://github.com/mmohammadi4820/Book_SoftwareEngineering_Tutorial)|[<p><img src="https://raw.githubusercontent.com/Mohammadimh76/Book_TensorFlow_Tutorial/main/Cover/Book_SoftwareTesting.jpeg"></p>](https://github.com/mmohammadi4820/Book_SoftwareTesting_Tutorial)|


</article>

</main>



